"""
YoloV8 Inference Service
========================

ServiÃ§o principal para inferÃªncia com modelos YoloV8.
"""

import os
import cv2
import glob
import shutil
from pathlib import Path
from typing import List, Dict, Any
from ultralytics import YOLO
import numpy as np
from config.settings import config


class YoloV8InferenceService:
    """ServiÃ§o de inferÃªncia YoloV8."""
    
    def __init__(self, model_path: str = None):
        """
        Inicializa o serviÃ§o de inferÃªncia.
        
        Args:
            model_path (str): Caminho para o modelo (.pt). Se None, usa modelo padrÃ£o
        """
        self.model_path = config.get_model_path(model_path or config.DEFAULT_MODEL)
        self.model = None
        self.output_dir = config.OUTPUT_DIR
        self.output_dir.mkdir(exist_ok=True)
        
        # Carrega o modelo
        self.load_model()
    
    def load_model(self):
        """
        Carrega o modelo YoloV8 local ou baixa automaticamente.
        
        Returns:
            None
        """
        try:
            print(f"ğŸ”„ Carregando modelo: {self.model_path}")
            
            # Caso 1: Modelo existe localmente
            if os.path.exists(self.model_path):
                self._load_local_model()
                return
            
            # Caso 2: Precisa baixar modelo prÃ©-treinado
            self._download_and_organize_model()
                
        except Exception as e:
            print(f"âŒ Erro ao carregar modelo: {e}")
            raise
    
    def _load_local_model(self):
        """
        Carrega modelo que jÃ¡ existe localmente.
        
        Returns:
            None
        """
        self.model = YOLO(self.model_path)
        print(f"âœ… Modelo carregado de: {self.model_path}")
    
    def _download_and_organize_model(self):
        """
        Baixa modelo prÃ©-treinado e organiza no diretÃ³rio correto.
        
        Returns:
            None
        """
        print(f"â¬‡ï¸  Baixando modelo prÃ©-treinado: {self.model_path}")
        
        # Carrega o modelo (que farÃ¡ o download automÃ¡tico na raiz)
        self.model = YOLO(self.model_path)
        
        # Verifica se precisa mover o modelo baixado
        downloaded_model = Path(self.model_path)
        if downloaded_model.exists() and not downloaded_model.is_absolute():
            self._move_downloaded_model(downloaded_model)
        
        print(f"âœ… Modelo baixado e carregado: {self.model_path}")
    
    def _move_downloaded_model(self, downloaded_model: Path):
        """
        Move modelo baixado para diretÃ³rio organizado.
        
        Args:
            downloaded_model (Path): Caminho do modelo baixado
            
        Returns:
            None
        """
        target_path = config.PRETRAINED_MODELS_DIR / downloaded_model.name
        
        try:
            shutil.move(str(downloaded_model), str(target_path))
            print(f"ğŸ“ Modelo movido para: {target_path}")
            
            # Atualiza o caminho do modelo e recarrega
            self.model_path = str(target_path)
            self.model = YOLO(str(target_path))
        except Exception as move_error:
            print(f"âš ï¸  Aviso: NÃ£o foi possÃ­vel mover o modelo: {move_error}")
    
    def run_inference_on_image(self, image_path: str, conf: float = 0.5) -> Dict[str, Any]:
        """
        Executa inferÃªncia em uma Ãºnica imagem.
        
        Args:
            image_path (str): Caminho para a imagem
            conf (float): Threshold de confianÃ§a
            
        Returns:
            result (Dict): DicionÃ¡rio com resultados da inferÃªncia
        """
        try:
            # Executa inferÃªncia
            results = self.model(image_path, conf=conf)
            result = results[0]  # Primeira (Ãºnica) imagem
            
            # Extrai informaÃ§Ãµes das detecÃ§Ãµes
            detections = self._extract_detections(result)
            
            # Salva imagem com detecÃ§Ãµes
            output_path = self.save_annotated_image(result, image_path)
            
            return self._build_success_response(image_path, output_path, detections, conf)
            
        except Exception as e:
            print(f"âŒ Erro na inferÃªncia de {image_path}: {e}")
            return self._build_error_response(image_path, str(e))
    
    def _extract_detections(self, result) -> List[Dict[str, Any]]:
        """
        Extrai informaÃ§Ãµes das detecÃ§Ãµes do resultado YoloV8.
        
        Args:
            result: Resultado da inferÃªncia YoloV8
            
        Returns:
            detections (List): Lista de detecÃ§Ãµes extraÃ­das
        """
        detections = []
        
        if result.boxes is None:
            return detections
        
        for i, box in enumerate(result.boxes):
            detection = {
                'class_id': int(box.cls[0]),
                'class_name': result.names[int(box.cls[0])],
                'confidence': float(box.conf[0]),
                'bbox': box.xyxy[0].tolist(),  # [x1, y1, x2, y2]
                'bbox_normalized': box.xywhn[0].tolist()  # [x_center, y_center, width, height] normalized
            }
            detections.append(detection)
        
        return detections
    
    def _build_success_response(self, image_path: str, output_path: str, 
                               detections: List[Dict], conf: float) -> Dict[str, Any]:
        """
        ConstrÃ³i resposta de sucesso da inferÃªncia.
        
        Args:
            image_path (str): Caminho da imagem original
            output_path (str): Caminho da imagem anotada
            detections (List): Lista de detecÃ§Ãµes
            conf (float): Threshold de confianÃ§a usado
            
        Returns:
            response (Dict): DicionÃ¡rio com resposta de sucesso
        """
        return {
            'image_path': image_path,
            'output_path': output_path,
            'detections_count': len(detections),
            'detections': detections,
            'model_used': self.model_path,
            'confidence_threshold': conf
        }
    
    def _build_error_response(self, image_path: str, error_message: str) -> Dict[str, Any]:
        """
        ConstrÃ³i resposta de erro da inferÃªncia.
        
        Args:
            image_path (str): Caminho da imagem que causou erro
            error_message (str): Mensagem de erro
            
        Returns:
            response (Dict): DicionÃ¡rio com resposta de erro
        """
        return {
            'image_path': image_path,
            'error': error_message,
            'detections_count': 0,
            'detections': []
        }
    
    def save_annotated_image(self, result, original_path: str) -> str:
        """
        Salva imagem com anotaÃ§Ãµes das detecÃ§Ãµes.
        
        Args:
            result: Resultado da inferÃªncia YoloV8
            original_path (str): Caminho da imagem original
            
        Returns:
            output_path (str): Caminho da imagem anotada salva
        """
        try:
            # Cria imagem anotada
            annotated_img = result.plot()
            
            # Define caminho de saÃ­da
            original_name = Path(original_path).stem
            output_path = self.output_dir / f"{original_name}_detected.jpg"
            
            # Salva imagem
            cv2.imwrite(str(output_path), annotated_img)
            
            return str(output_path)
            
        except Exception as e:
            print(f"âš ï¸  Erro ao salvar imagem anotada: {e}")
            return ""
    
    def run_inference_on_folder(self, folder_path: str, conf: float = 0.5) -> List[Dict[str, Any]]:
        """
        Executa inferÃªncia em todas as imagens de uma pasta.
        
        Args:
            folder_path (str): Caminho para a pasta com imagens
            conf (float): Threshold de confianÃ§a
            
        Returns:
            results (List): Lista com resultados de todas as imagens
        """
        # Busca todas as imagens na pasta
        image_files = self._find_image_files(folder_path)
        
        if not image_files:
            print(f"âš ï¸  Nenhuma imagem encontrada em: {folder_path}")
            return []
        
        print(f"ğŸ–¼ï¸  Encontradas {len(image_files)} imagens para processar")
        
        # Processa cada imagem
        return self._process_all_images(image_files, conf)
    
    def _find_image_files(self, folder_path: str) -> List[str]:
        """
        Encontra todos os arquivos de imagem na pasta.
        
        Args:
            folder_path (str): Caminho da pasta
            
        Returns:
            image_files (List): Lista de caminhos de imagens encontradas
        """
        # Usa extensÃµes da configuraÃ§Ã£o
        image_extensions = [f"*{ext}" for ext in config.SUPPORTED_IMAGE_EXTENSIONS]
        
        # Encontra todas as imagens (usando set para evitar duplicatas)
        image_files = set()
        for ext in image_extensions:
            image_files.update(glob.glob(os.path.join(folder_path, ext)))
            image_files.update(glob.glob(os.path.join(folder_path, ext.upper())))
        
        # Converte para lista e ordena
        return sorted(list(image_files))
    
    def _process_all_images(self, image_files: List[str], conf: float) -> List[Dict[str, Any]]:
        """
        Processa lista de imagens com inferÃªncia.
        
        Args:
            image_files (List): Lista de caminhos de imagens
            conf (float): Threshold de confianÃ§a
            
        Returns:
            results (List): Lista com resultados de todas as imagens
        """
        all_results = []
        
        for i, image_path in enumerate(image_files, 1):
            print(f"ğŸ“· Processando ({i}/{len(image_files)}): {os.path.basename(image_path)}")
            result = self.run_inference_on_image(image_path, conf)
            all_results.append(result)
        
        return all_results
